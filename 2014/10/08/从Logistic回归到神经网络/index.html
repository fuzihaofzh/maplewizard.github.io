<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="BdchXXdzLi" />
  <meta name="google-site-verification" content="Js0CGXsHxNJBkQ55HoUIwJx6TuBtGbDARK2QTTE7DLA" />
  
  <title>从Logistic回归到神经网络 | 切问录</title>
  <meta name="author" content="Z.H. Fu">
  
  <meta name="description" content="从Logistic回归到神经网络By Z.H. Fu切问录 maplewizard.github.io  

sigmoid函数sigmoid函数定义为$$g(z)=\frac{1}{1+e^{-z}}$$对于一般的模型，通常有$z=\theta^{\mathrm{T}}x$，可以看做是样本各属性的加权。sigmoid函数求导有$g’(z)=g(z)(1-g(z))$，这个在神经网络推导的时候会用到。
Logistic回归Logistic回归是针对二分类问题常用的一种回归，其回归模型为：$$h_\theta(x)=\frac{1}{1+e^{-\theta^{\mathrm{T}}x}}$$其中$x$是某个样本的属性向量，$\theta$是参数向量。在用Logistic回归时，需要找到合适的参数$\theta$，使得能量函数（误差）$J(\theta)$最小，在使用梯度下降法更新参数$\theta$的更新过程中需要使用到梯度，然后在每一步执行$\theta:=\theta-\alpha\nabla_\theta J(\theta)$，其中$\alpha是学习速度$，能量函数被定义为：$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))\right]$$其中$$h_{\theta}(x^{(i)})=\frac{1}{1+e^{-\theta^{\mathrm{T}}x^{(i)}}}$$下面来给出其梯度的推导">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="从Logistic回归到神经网络"/>
  <meta property="og:site_name" content="切问录"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/blog/images/favicon.png" rel="icon">
  <link rel="alternate" href="/blog/atom.xml" title="切问录" type="application/atom+xml">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F2489a13dce6ecb0fb337a44cf06a0e6e' type='text/javascript'%3E%3C/script%3E"));
</script>


<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'true']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

  
    <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  
</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/blog/">切问录</a></h1>
  <h2><a href="/blog/">$\mathscr{MATH\quad IS\quad FUN}$</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">主页</a></li>
    
      <li><a href="/archives">归档</a></li>
    
      <li><a href="/about">关于</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-10-08T14:24:43.000Z"><a href="/blog/2014/10/08/从Logistic回归到神经网络/">2014-10-08</a></time>
      
      
  
    <h1 class="title">从Logistic回归到神经网络</h1>
  

    </header>
    <div class="entry">
      
        <h1 id="从Logistic回归到神经网络"><center>从Logistic回归到神经网络</center></h1><center>By Z.H. Fu</center><br><center>切问录 <a href="http://maplewizard.github.io" target="_blank" rel="external">maplewizard.github.io</a>  </center>

<h2 id="sigmoid函数">sigmoid函数</h2><p>sigmoid函数定义为<br>$$g(z)=\frac{1}{1+e^{-z}}$$<br>对于一般的模型，通常有$z=\theta^{\mathrm{T}}x$，可以看做是样本各属性的加权。sigmoid函数求导有$g’(z)=g(z)(1-g(z))$，这个在神经网络推导的时候会用到。</p>
<h2 id="Logistic回归">Logistic回归</h2><p>Logistic回归是针对二分类问题常用的一种回归，其回归模型为：<br>$$h_\theta(x)=\frac{1}{1+e^{-\theta^{\mathrm{T}}x}}$$<br>其中$x$是某个样本的属性向量，$\theta$是参数向量。在用Logistic回归时，需要找到合适的参数$\theta$，使得能量函数（误差）$J(\theta)$最小，在使用梯度下降法更新参数$\theta$的更新过程中需要使用到梯度，然后在每一步执行$\theta:=\theta-\alpha\nabla_\theta J(\theta)$，其中$\alpha是学习速度$，能量函数被定义为：<br>$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))\right]$$<br>其中<br>$$h_{\theta}(x^{(i)})=\frac{1}{1+e^{-\theta^{\mathrm{T}}x^{(i)}}}$$<br>下面来给出其梯度的推导<br><a id="more"></a><br>$$\begin{align}\frac{\partial}{\partial \theta_j} &amp;=<br>-\frac{\partial}{\partial \theta_j}\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))\right] \\<br>&amp;= -\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\frac{\partial}{\partial \theta_j}\log h_{\theta}(x^{(i)})+(1-y^{(i)})\frac{\partial}{\partial \theta_j}\log (1-h_{\theta}(x^{(i)}))\right] \\<br>&amp;= -\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{\partial}{\partial \theta_j} h_{\theta}(x^{(i)})+(1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{\partial}{\partial \theta_j} (1-h_{\theta}(x^{(i)}))\right] \\<br>&amp;= -\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{e^{-\theta^{\mathrm{T}}x}x^{(i)}_j}{(1+e^{-\theta^{\mathrm{T}}x})^2} +(1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{e^{-\theta^{\mathrm{T}}x}x^{(i)}_j}{(1+e^{-\theta^{\mathrm{T}}x})^2}\right] \\<br>&amp;= -\frac{1}{m}\sum_{i=1}^m\left[y^{(i)}\frac{e^{-\theta^{\mathrm{T}}x}x^{(i)}_j}{1+e^{-\theta^{\mathrm{T}}x}} -(1-y^{(i)})\frac{x^{(i)}_j}{1+e^{-\theta^{\mathrm{T}}x}}\right] \\<br>\end{align}$$<br>由上式可知<br>$$\frac{\partial}{\partial \theta_j}=\left{ \begin{aligned}<br>   \frac{1}{m}\sum_{i=1}^m\left[ \frac{x^{(i)}_j}{1+e^{-\theta^{\mathrm{T}}x}}\right]\quad y^{(i)}=0\\<br>  -\frac{1}{m}\sum_{i=1}^m\left[(1-\frac{1}{1+e^{-\theta^{\mathrm{T}}x}})x^{(i)}_j \right]\quad y^{(i)}=1<br>\end{aligned} \right.$$<br>$$\frac{\partial}{\partial \theta_j}=\left{ \begin{aligned}<br>   \frac{1}{m}\sum_{i=1}^m\left[ (h_{\theta}(x^{(i)})-0)x^{(i)}_j\right]\quad y^{(i)}=0\\<br>  \frac{1}{m}\sum_{i=1}^m\left[(h_{\theta}(x^{(i)})-1)x^{(i)}_j \right]\quad y^{(i)}=1<br>\end{aligned} \right.$$<br>综上<br>$$\frac{\partial}{\partial \theta_j}=\frac{1}{m}\sum_{i=1}^m\left[(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_j\right]$$<br>我们来给出这个式子的直观的理解。对于每个样本，每个$\theta_j$的梯度等于误差乘上该样本的第$j$个属性，最后再把每个样本得到的东西平均一下。我们有了这个直观的理解，就可以直接来理解神经网络的Back Propogation了。</p>
<h2 id="神经网络">神经网络</h2><p>神经网络其实就相当于很多个Logistic回归器并在了一起，然后加了很多层。下面来理解神经网络的Back Propogation。我们按照这个理解，我们首先来规定符号，记第$l$层网络的第$j$个节点的计算值为$a^{(l)}_j$，而$\Theta^{(l)}_{ij}$表示的是第$l$层神经网络的第$j$个元素传递到下一层的第$i$个元素的影响系数我们有：<br>$$\begin{align}&amp;a^{(1)}=x\\<br>&amp;z^{(2)}=\Theta^{(1)}a^{(1)}\\<br>&amp;a^{(2)}=g(z^{(2)})\\<br>&amp;z^{(3)}=\Theta^{(2)}a^{(2)}\\<br>&amp;a^{(3)}=g(z^{(3)})\\<br>&amp;z^{(4)}=\Theta^{(3)}a^{(3)}\\<br>&amp;a^{(4)}=g(z^{(4)})\\<br>\end{align}$$<br>通过Logistic的例子我们发现，要计算参数$\Theta$的梯度，关键是要计算出误差值，下面，我们来讨论误差值的计算。最后一层的误差是已知的，我们用一种Back Propogation的方法从后往前倒推每一层的误差。令$\delta^{(l)}_j$表示第$l$层第$j$个元素的误差，假设最后一层是第四层，那么有$\delta^{(4)}_j=a^{(4)}_j-y_j$。那么我们已知第$l+1$层的误差，如何找到第$l$层的误差？这就要通过一个误差传递的方法。一个基本的想法是，如果一个输入对误差造成的影响很大，那么这个输入所在的线路的权值就应该很大，这个权值则可以通过对该点的值求偏导得到。我们有<br>$$\delta^{(3)}=(\Theta^{(3)})^{\mathrm{T}}\delta^{(4)}._g’(z^{(3)})\\<br>\delta^{(2)}=(\Theta^{(2)})^{\mathrm{T}}\delta^{(3)}._g’(z^{(2)})$$<br>回忆sigmoid函数的导数可知<br>$$g’(z^{(3)})=a^{(3)}._(1-a^{(3)})\\<br>g’(z^{(2)})=a^{(2)}._(1-a^{(2)})$$<br>我们在得到误差后，则可以得到$\Theta$的梯度。有<br>$$\frac{\partial}{\partial \Theta^{(l)}_{ij}}=\frac{1}{m}\sum_{k=1}^m a^{l}_{jk}\delta^{(l+1)}_{ik}$$<br>其中求和表示对每一个样本进行，$k$即表示样本编号。有了这个偏导之后便可对参数$\Theta$进行梯度下降。<br>在实际使用中，需要在能量函数中加入偏置和一些参数的限制，可参考相关书籍介绍。</p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/blog/categories/机器学习/">机器学习</a>
  </div>

        
  
  <div class="tags">
    <a href="/blog/tags/Logistic/">Logistic</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">

<!-- Duoshuo Comment BEGIN -->
  <div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"maplewizard"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- Duoshuo Comment END -->

  <h1 class="title">留言</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://fuzihao.org/blog/blog/2014/10/08/从Logistic回归到神经网络/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:fuzihao.org/blog">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/blog/2015/02/19/org-mode教程/">org-mode入门教程</a>
      </li>
    
      <li>
        <a href="/blog/2015/01/17/互信息的理解/">互信息的理解</a>
      </li>
    
      <li>
        <a href="/blog/2014/10/23/仿射空间与仿射变换/">仿射空间与仿射变换</a>
      </li>
    
      <li>
        <a href="/blog/2014/10/23/用chrome修改js代码/">用chrome修改js代码</a>
      </li>
    
      <li>
        <a href="/blog/2014/10/08/从Logistic回归到神经网络/">从Logistic回归到神经网络</a>
      </li>
    
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/blog/categories/C/">C++</a><small>1</small></li>
  
    <li><a href="/blog/categories/Fortran/">Fortran</a><small>1</small></li>
  
    <li><a href="/blog/categories/Hexo/">Hexo</a><small>1</small></li>
  
    <li><a href="/blog/categories/Intuitive-Math/">Intuitive Math</a><small>2</small></li>
  
    <li><a href="/blog/categories/LaTeX/">LaTeX</a><small>1</small></li>
  
    <li><a href="/blog/categories/Linux/">Linux</a><small>1</small></li>
  
    <li><a href="/blog/categories/Python/">Python</a><small>3</small></li>
  
    <li><a href="/blog/categories/历史/">历史</a><small>2</small></li>
  
    <li><a href="/blog/categories/图像处理/">图像处理</a><small>2</small></li>
  
    <li><a href="/blog/categories/工具应用/">工具应用</a><small>1</small></li>
  
    <li><a href="/blog/categories/数学杂谈/">数学杂谈</a><small>13</small></li>
  
    <li><a href="/blog/categories/有限元/">有限元</a><small>1</small></li>
  
    <li><a href="/blog/categories/机器学习/">机器学习</a><small>1</small></li>
  
    <li><a href="/blog/categories/物理随笔/">物理随笔</a><small>2</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/blog/tags/Bernstein多项式/" style="font-size: 10px;">Bernstein多项式</a><a href="/blog/tags/Bezier曲线/" style="font-size: 10px;">Bézier曲线</a><a href="/blog/tags/C/" style="font-size: 10px;">C++</a><a href="/blog/tags/Emacs/" style="font-size: 10px;">Emacs</a><a href="/blog/tags/Fortran/" style="font-size: 10px;">Fortran</a><a href="/blog/tags/LaTeX/" style="font-size: 15px;">LaTeX</a><a href="/blog/tags/Logistic/" style="font-size: 10px;">Logistic</a><a href="/blog/tags/Python/" style="font-size: 20px;">Python</a><a href="/blog/tags/beamer/" style="font-size: 10px;">beamer</a><a href="/blog/tags/chrome/" style="font-size: 10px;">chrome</a><a href="/blog/tags/markdown/" style="font-size: 10px;">markdown</a><a href="/blog/tags/marked/" style="font-size: 10px;">marked</a><a href="/blog/tags/mathJax/" style="font-size: 10px;">mathJax</a><a href="/blog/tags/matplotlib/" style="font-size: 20px;">matplotlib</a><a href="/blog/tags/互信息/" style="font-size: 10px;">互信息</a><a href="/blog/tags/仿射变换/" style="font-size: 10px;">仿射变换</a><a href="/blog/tags/优化/" style="font-size: 10px;">优化</a><a href="/blog/tags/历史/" style="font-size: 15px;">历史</a><a href="/blog/tags/变分法/" style="font-size: 15px;">变分法</a><a href="/blog/tags/国史大纲/" style="font-size: 10px;">国史大纲</a><a href="/blog/tags/奇异值分解/" style="font-size: 10px;">奇异值分解</a><a href="/blog/tags/并行计算/" style="font-size: 10px;">并行计算</a><a href="/blog/tags/张量，度量张量/" style="font-size: 10px;">张量，度量张量</a><a href="/blog/tags/形态学/" style="font-size: 10px;">形态学</a><a href="/blog/tags/微积分/" style="font-size: 10px;">微积分</a><a href="/blog/tags/惯性矩/" style="font-size: 10px;">惯性矩</a><a href="/blog/tags/拉普拉斯变换/" style="font-size: 10px;">拉普拉斯变换</a><a href="/blog/tags/散度定理/" style="font-size: 10px;">散度定理</a><a href="/blog/tags/数据压缩/" style="font-size: 10px;">数据压缩</a><a href="/blog/tags/斐波那契数列/" style="font-size: 10px;">斐波那契数列</a><a href="/blog/tags/最小二乘/" style="font-size: 10px;">最小二乘</a><a href="/blog/tags/有限元/" style="font-size: 10px;">有限元</a><a href="/blog/tags/机器学习/" style="font-size: 10px;">机器学习</a><a href="/blog/tags/样条曲线/" style="font-size: 10px;">样条曲线</a><a href="/blog/tags/格林公式/" style="font-size: 10px;">格林公式</a><a href="/blog/tags/格林恒等式/" style="font-size: 10px;">格林恒等式</a><a href="/blog/tags/概率/" style="font-size: 10px;">概率</a><a href="/blog/tags/正定矩阵/" style="font-size: 10px;">正定矩阵</a><a href="/blog/tags/海森矩阵，最小作用量/" style="font-size: 10px;">海森矩阵，最小作用量</a><a href="/blog/tags/点云重建/" style="font-size: 10px;">点云重建</a><a href="/blog/tags/积分/" style="font-size: 15px;">积分</a><a href="/blog/tags/线性代数/" style="font-size: 15px;">线性代数</a><a href="/blog/tags/组合数学/" style="font-size: 10px;">组合数学</a><a href="/blog/tags/读书笔记/" style="font-size: 10px;">读书笔记</a><a href="/blog/tags/雅克比矩阵/" style="font-size: 10px;">雅克比矩阵</a>
  </div>
</div>


  <div class="widget tag">
<h3 class="title">友情链接</h3>
<ul class="entry">
<li><a href="http://zipperary.com/" title="Zippera's Blog">Zippera</a></li>
<li><a href="http://www.lixthu.com/" title="La Fantasia">La Fantasia</a></li>
<li><a href="http://zh.lucida.me/" title="lucida">lucida</a></li>
<li><a href="http://zhiqiang.org/blog/" title="阅微堂">阅微堂</a></li>
<li><a href="http://lukang.me/" title="Kang Lu' Blog">Kang Lu' Blog</a></li>
</ul>
</div>


  <div class="widget recent comments">
<h3 class="title">最新评论</h3>
<ul class="ds-recent-comments" data-num-items="10" data-show-avatars="1" data-show-time="1" data-show-admin="1" data-excerpt-length="70"></ul>
<!--多说js加载开始，一个页面只需要加载一次 -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"maplewizard"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script>
<!--多说js加载结束，一个页面只需要加载一次 -->
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 Z.H. Fu
  
</div>
<div class="clearfix"></div></footer>
  <script src="/blog/js/jquery.min.js"></script>
<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>




<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


</body>
</html>